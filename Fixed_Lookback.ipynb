{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f248ddf3",
      "metadata": {
        "id": "f248ddf3"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aca0128a",
      "metadata": {
        "id": "aca0128a"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abc50fe5",
      "metadata": {
        "id": "abc50fe5"
      },
      "outputs": [],
      "source": [
        "def get_data(arr, residue_list, q8_list, columns, r, f, bounds=None):\n",
        "    \n",
        "    \"\"\"\n",
        "    This function retrieves and formats data from the CB6133_filtered and CB531 datasets [1][2]\n",
        "    Codes is slighlty modified from code provided by [3][4]\n",
        "    \n",
        "    [1] Jian Zhou and Olga G. Troyanskaya. Deep supervised and convolutional generative stochastic network for\n",
        "        protein s\n",
        "    [2] Jian Zhou and Olga G. Troyanskaya. CB6133 dataset.\n",
        "        https://www.princeton.edu/~jzthree/datasets/ICML2014/dataset_readme.txt, 2014.\n",
        "    [3] Iddo Drori et al. High Quality Prediction of Protein Q8 Secondary Structure by\n",
        "        Diverse Neural Network Architectures. arXiv preprint arXiv:1811.07143, 2018\n",
        "    [4] https://github.com/idrori/cu-ssp/blob/master/model_1/model_1.py\n",
        "    \"\"\"\n",
        "    \n",
        "    if bounds is None: bounds = range(len(arr))\n",
        "    \n",
        "    data = [None for i in bounds]\n",
        "    for i in bounds:\n",
        "        seq, q8, q3, q2, profiles = '', '', '', '', []\n",
        "        for j in range(r):\n",
        "            jf = j*f\n",
        "            \n",
        "            # Residue convert from one-hot to decoded\n",
        "            residue_onehot = arr[i,jf+0:jf+22]\n",
        "            residue = residue_list[np.argmax(residue_onehot)]\n",
        "\n",
        "            # Q8 one-hot encoded to decoded structure symbol\n",
        "            residue_q8_onehot = arr[i,jf+22:jf+31]\n",
        "            residue_q8 = q8_list[np.argmax(residue_q8_onehot)]\n",
        "\n",
        "            if residue == 'NoSeq': break      # terminating sequence symbol\n",
        "\n",
        "            nc_terminals = arr[i,jf+31:jf+33] # nc_terminals = [0. 0.]\n",
        "            sa = arr[i,jf+33:jf+35]           # sa = [0. 0.]\n",
        "            profile = arr[i,jf+35:jf+57]      # profile features\n",
        "            \n",
        "            seq += residue # concat residues into amino acid sequence\n",
        "\n",
        "            #encode q3 structure\n",
        "            if residue_q8 in 'GHI':\n",
        "                q3 += 'H'\n",
        "                q2 += 'A'\n",
        "            elif residue_q8 in 'TBSL':\n",
        "                q3 += 'C'\n",
        "                q2 += 'X'\n",
        "            elif residue_q8 in 'E':\n",
        "                q3 += 'E'\n",
        "                q2 += 'X'\n",
        "            else:\n",
        "                q3 += 'Z'\n",
        "                q2 += 'Z'\n",
        "            \n",
        "            q8  += residue_q8 # concat secondary structure into secondary structure sequence\n",
        "            profiles.append(profile)\n",
        "        \n",
        "        data[i] = [str(i+1), len(seq), seq, np.array(profiles), q8, q3, q2]\n",
        "    \n",
        "    return pd.DataFrame(data, columns=columns)\n",
        "\n",
        "\n",
        "def encode_sequence(sequence, code):\n",
        "    \n",
        "    \"\"\"\n",
        "    Provided an input sequence and a code, returns the encoding of the sequence\n",
        "    \"\"\"\n",
        "    \n",
        "    encoded_seq = []\n",
        "    \n",
        "    for x in sequence:\n",
        "        try:\n",
        "            idx = code[x]\n",
        "            encoded_seq.append(idx)\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            break\n",
        "    \n",
        "    return encoded_seq\n",
        "\n",
        "\n",
        "def format_dataset(df, emission_code, state_code, exp_col=\"q3_expected\"):\n",
        "    \n",
        "    \"\"\"\n",
        "    Provided a dataframe which contains the amino sequences and the hidden sequence,\n",
        "    this function encodes those sequences according to the provided codes\n",
        "    and return them\n",
        "    \n",
        "    *exp_col specifies if want to encode the q8, q3, or q2 hidden sequence\n",
        "    \"\"\"\n",
        "    \n",
        "    assert ('id' in df.columns and 'len' in df.columns and 'input' in df.columns and exp_col in df.columns)\n",
        "    \n",
        "    formattedDF = pd.DataFrame(columns=['id','len','input','expected'])\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        \n",
        "        sid = df.iloc[i].id\n",
        "        slen = df.iloc[i].len\n",
        "        enc_input = encode_sequence(df.iloc[i].input, emission_code)\n",
        "        enc_expected = encode_sequence(df.iloc[i][exp_col], state_code)\n",
        "        \n",
        "        assert (len(enc_input) == len(enc_expected))\n",
        "        \n",
        "        formattedDF = formattedDF.append({'id':sid, 'len':slen, 'input':enc_input, 'expected':enc_expected}, ignore_index=True)\n",
        "\n",
        "    return formattedDF\n",
        "\n",
        "def estimate_transition_matrix(df, state_code):\n",
        "    \"\"\"\n",
        "    Given a dataframe that has the data for the amino sequences and their corresponding hidden sequence,\n",
        "    we use the data to compute the MLEs of the emission probablities.\n",
        "    \n",
        "    ex. estimated P(emission=A|state=H) = count(emission=A,state=H) / sum_over_all_emission count(emission, state=H)\n",
        "    \n",
        "    *implemented a pseudocount of +1 for cases where we have 0 observations of a certain (emission,state) combo\n",
        "    \"\"\"\n",
        "    \n",
        "    n_states = len(state_code)\n",
        "    \n",
        "    #using pseudocount of +1\n",
        "    counts = np.ones(shape=(n_states, n_states), dtype=float)\n",
        "    \n",
        "    for i in range(len(df)):\n",
        "        \n",
        "        state_seq = df.iloc[i].expected\n",
        "        seq_len = len(df.iloc[i].expected)\n",
        "        \n",
        "        for j in range(seq_len - 1):\n",
        "            \n",
        "            x = state_seq[j]\n",
        "            y = state_seq[j+1]\n",
        "            \n",
        "            counts[x,y] += 1\n",
        "    \n",
        "    #transform counts to probability by normalizing of row sums\n",
        "    row_sums = np.sum(counts, axis=1)\n",
        "    T = counts / row_sums.reshape((-1,1))\n",
        "    \n",
        "    return T\n",
        "\n",
        "\n",
        "def estimate_emission_matrix(df, state_code, emission_code):\n",
        "    \"\"\"\n",
        "    Given a dataframe that has the data for the amino sequences and their corresponding hidden sequence,\n",
        "    we use the data to compute the MLEs of the transition probablities.\n",
        "    \n",
        "    ex. estimated P(state_{t+1}=E|state_{t}=H) = count(state_{t}=H, state_{t+1}=E) / sum_over_all_states count(state_{t}=H, state_{t+1})\n",
        "    \n",
        "    *implemented a pseudocount of +1 for cases where we have 0 observations of a certain (state,state) combo\n",
        "    \"\"\"\n",
        "    \n",
        "    n_states = len(state_code)\n",
        "    n_emissions = len(emission_code)\n",
        "    \n",
        "    #using pseudocount of +1\n",
        "    #Steve Contribution\n",
        "    #Change counts matrix to be n_states x n_emissions x n_emissions\n",
        "    #Each state has a n_emissions x n_emissions context-dependent matrix associated with it\n",
        "    counts = np.ones(shape=(n_states, n_emissions, n_emissions), dtype=float)\n",
        "    \n",
        "    for i in range(len(df)):\n",
        "        \n",
        "        state_seq = df.iloc[i].expected\n",
        "        #emission_seq now of form: [(1,4),(2,5),...]\n",
        "        #store context in y\n",
        "        #store new state in z\n",
        "        emission_seq = df.iloc[i].input\n",
        "        #df['len'] no longer reflects true length\n",
        "        seq_len = len(df.iloc[i].input)\n",
        "        \n",
        "        for j in range(seq_len):\n",
        "            \n",
        "            x = state_seq[j]\n",
        "            y = emission_seq[j][0]\n",
        "            z = emission_seq[j][1]\n",
        "            \n",
        "            counts[x,y,z] += 1\n",
        "\n",
        "    #transform counts to probability by normalizing of row sums\n",
        "    #not sure how pendo's way works, implementing my own here\n",
        "    #index y is 'context', normalize by this row\n",
        "    for i in range(counts.shape[0]):\n",
        "        for j in range(counts.shape[1]):\n",
        "            counts[i,j,:] = counts[i,j,:]/np.sum(counts[i,j,:])\n",
        "    \n",
        "    E = counts\n",
        "    \n",
        "    #row_sums = np.sum(counts, axis=1)\n",
        "    #print(row_sums.shape)\n",
        "    #E = counts / row_sums.reshape((-1,3))\n",
        "\n",
        "    return E\n",
        "\n",
        "def start_distribution(df,state_code):\n",
        "    \"\"\"\n",
        "    Given a dataframe that has the data for the amino sequences and their corresponding hidden sequence,\n",
        "    we use the data to compute the MLEs of the start distribution.\n",
        "    \n",
        "    ex. estimated P(state=H) = count(state=H) / sum_over_all_states count(state)\n",
        "    \n",
        "    *implemented a pseudocount of +1 for cases where we have 0 observations of a certain state\n",
        "    \"\"\"\n",
        "    \n",
        "    n_states = len(state_code)\n",
        "    \n",
        "    #using pseudocount of +1\n",
        "    counts = np.array([1.0] * n_states)\n",
        "    \n",
        "    for i in range(len(df)):\n",
        "        \n",
        "        state_seq = df.iloc[i].expected\n",
        "        seq_len = len(df.iloc[i].expected)\n",
        "        \n",
        "        for j in range(seq_len):\n",
        "            \n",
        "            x = state_seq[j]\n",
        "            \n",
        "            counts[x] += 1\n",
        "    \n",
        "    #transform counts to probability by normalizing of row sums\n",
        "    total = sum(counts)\n",
        "    pi = counts / total\n",
        "    \n",
        "    return pi\n",
        "\n",
        "def viterbi_decoding(T,E,pi,seq):\n",
        "    \"\"\"\n",
        "    This functions performs viterbi decoding to get the predicted hidden sequence,\n",
        "    given the input emission sequence as well as the transition matrix, emission matrix,\n",
        "    and the start distribution\n",
        "    \"\"\"\n",
        "    \n",
        "    #sequence length\n",
        "    N = len(seq)\n",
        "    #num of states\n",
        "    M = T.shape[0]\n",
        "    \n",
        "    assert (M == len(pi))\n",
        "    \n",
        "    #V will store viterbi values\n",
        "    V = np.zeros(shape=(M, N), dtype=float)\n",
        "    \n",
        "    #P will store prev state from which we transitioned into state m and time n to achieve the max value of V[m,n]\n",
        "    #(i.e. pointer to help us reconstruct sequence after predicting most probable path in viterbi graph)\n",
        "    P = np.empty(shape=(M, N))\n",
        "    P[:] = np.NaN\n",
        "    \n",
        "    #populate viterbi matrix\n",
        "    for n in range(N):\n",
        "        \n",
        "        #get current emissions\n",
        "        e = seq[n]\n",
        "        \n",
        "        for m in range(M):\n",
        "            \n",
        "            #initilize viterbi value for current timestep given state m to be -infty\n",
        "            maxV = float(\"-inf\")\n",
        "            prev = np.NaN\n",
        "            \n",
        "            #get log prob. of emission given state m\n",
        "            emiss_logp = np.log(E[m,e[0],e[1]])\n",
        "            \n",
        "            #start of sequence\n",
        "            if n == 0:\n",
        "                start_logp = np.log(pi[m])\n",
        "                maxV = emiss_logp + start_logp\n",
        "                \n",
        "            else:\n",
        "            \n",
        "                #solve for max value for V[m,n]\n",
        "                for i in range(M): \n",
        "\n",
        "                    #get previous timestep viterbi value for state i (which should be a log prob)\n",
        "                    prev_vit = V[i, n-1]\n",
        "\n",
        "                    #get log prob of transition from state i to m\n",
        "                    trans_logp = np.log(T[i,m])\n",
        "\n",
        "                    #update viterbi value for current timestep given state m\n",
        "                    curV = prev_vit + trans_logp + emiss_logp\n",
        "\n",
        "                    if curV > maxV:\n",
        "                        maxV = curV\n",
        "                        prev = i\n",
        "        \n",
        "            V[m,n] = maxV\n",
        "            P[m,n] = prev\n",
        "    \n",
        "    #initialize with state with highest probability at end of sequence\n",
        "    best_path = [np.argmax(V[:,-1])]\n",
        "    \n",
        "    #work backwards to reconstruct sequence\n",
        "    for n in range(N-1,0,-1):\n",
        "        \n",
        "        #determine where we are\n",
        "        cur_state = best_path[0]\n",
        "\n",
        "        #find state from which we came that yielded highest probability to current state at current time\n",
        "        prev_state = int(P[cur_state,n])\n",
        "\n",
        "        #prepend previous state\n",
        "        best_path = [prev_state] + best_path\n",
        "    \n",
        "    return best_path\n",
        "\n",
        "\n",
        "def getPredictions(df, T, E, pi):\n",
        "    \n",
        "    \"\"\"\n",
        "    get predictions for all sequences in specified dataset using provided HMM\n",
        "    \"\"\"\n",
        "    \n",
        "    results = pd.DataFrame(columns=['input','predicted','expected'])\n",
        "    \n",
        "    for i in range(len(df)):\n",
        "        \n",
        "        #change amino_seq input\n",
        "        amino_seq = df.iloc[i].input\n",
        "        pred_seq = viterbi_decoding(T,E,pi,amino_seq)\n",
        "        exp_seq = df.iloc[i].expected\n",
        "        \n",
        "        #Steve commented this out because we are padding our start with new symbols\n",
        "        #assert(len(amino_seq) == len(pred_seq) and len(amino_seq) == len(exp_seq))\n",
        "        \n",
        "        results = results.append({'input':amino_seq, 'predicted':pred_seq, 'expected':exp_seq}, ignore_index=True)\n",
        "    \n",
        "    return results\n",
        "\n",
        "def HMMaccuracy(df,q=3):\n",
        "    \n",
        "    \"\"\"\n",
        "    Compute accurcay of HMM given a dataframe the has the input emission sequences,\n",
        "    the predicted hidden sequences, and the actual hidden sequences\n",
        "    \n",
        "    *q specifies whether the predicion was made for q2, q3, or q8 protein structure\n",
        "    \"\"\"\n",
        "    \n",
        "    #row represents expected state\n",
        "    #col represents predicted state\n",
        "    counts = np.zeros(shape=(q,q), dtype=int)\n",
        "    \n",
        "    for i in range(len(df)):\n",
        "\n",
        "        #get predicted and expected hidden sequence from dataframe\n",
        "        pred = df.iloc[i].predicted\n",
        "        exp = df.iloc[i].expected\n",
        "        \n",
        "        #assert (len(pred) == len(exp))\n",
        "        \n",
        "        for j in range(len(pred)):\n",
        "            \n",
        "            x = exp[j]\n",
        "            y = pred[j]\n",
        "            counts[x,y] += 1\n",
        "    \n",
        "    rowSum = np.sum(counts, axis=1)\n",
        "    colSum = np.sum(counts, axis=0)\n",
        "    \n",
        "    #true positive (negative) / total predicted positive (negative)\n",
        "    precision = np.array([counts[i,i] / colSum[i] for i in range(q)])\n",
        "    \n",
        "    #true positive (negative) / total actual positive (negative)\n",
        "    recall = np.array([counts[i,i] / rowSum[i] for i in range(q)])\n",
        "    \n",
        "    accuracy = 0\n",
        "    for i in range(q):\n",
        "        accuracy += counts[i,i]\n",
        "    accuracy = accuracy / sum(rowSum)\n",
        "    \n",
        "    \n",
        "    return accuracy, precision, recall, counts\n",
        "\n",
        "\n",
        "\n",
        "# Steve contributions\n",
        "\n",
        "#Encode context by keeping track of the i-4'th residue\n",
        "\n",
        "def encode_seq_context(sequence,spacing = 4):\n",
        "    encoded_sequence = []\n",
        "    for i in range(spacing,len(sequence)):\n",
        "        encoded_sequence.append((sequence[i-spacing],sequence[i]))\n",
        "    \n",
        "    return encoded_sequence\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "984ee1c9",
      "metadata": {
        "id": "984ee1c9"
      },
      "source": [
        "Step 1: Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a55243b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "a55243b5",
        "outputId": "70746b7d-1b48-4f18-af67-91425197cd7d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5f2a3c87eb29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcb513\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cb513+profile_split1.npy.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcb6133filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cullpdb+profile_5926_filtered.npy.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data Loaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cb513+profile_split1.npy.gz'"
          ]
        }
      ],
      "source": [
        "#seed so get consistent results for every run\n",
        "random.seed(0)\n",
        "\n",
        "cb513 = np.load('cb513+profile_split1.npy.gz')\n",
        "cb6133filtered = np.load('cullpdb+profile_5926_filtered.npy.gz')\n",
        "print(\"Data Loaded\")\n",
        "print(f\"CB6133 shape: {cb6133filtered.shape}\")\n",
        "print(f\"CB513 shape: {cb513.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c910596f",
      "metadata": {
        "id": "c910596f"
      },
      "source": [
        "### Step 2: Process Data\n",
        "    & split into train, dev, and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "091dae2b",
      "metadata": {
        "id": "091dae2b",
        "outputId": "667ac406-5ce2-498b-a6f0-0c372f82010d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Turning data arrays into dataframes\n"
          ]
        }
      ],
      "source": [
        "maxlen_seq = r = 700 # protein residues padded to 700\n",
        "f = 57  # number of features for each residue\n",
        "\n",
        "residue_list = list('ARNDCEQGHILKMFPSTWYVX') + ['NoSeq']\n",
        "q8_list      = list('LBEGIHST') + ['NoSeq']\n",
        "q3_list      = list('HCE') + ['NoSeq']\n",
        "q2_list      = list('AX') + ['NoSeq']\n",
        "\n",
        "columns = [\"id\", \"len\", \"input\", \"profiles\", \"q8_expected\", \"q3_expected\", \"q2_expected\"]\n",
        "\n",
        "print(\"Turning data arrays into dataframes\")\n",
        "\n",
        "# train, dev, test split\n",
        "# break out 10% of train data to be used as dev set\n",
        "train_df, dev_df = train_test_split(get_data(cb6133filtered, residue_list, q8_list, columns, r, f), test_size=0.1)\n",
        "test_df  = get_data(cb513, residue_list, q8_list, columns, r, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73751055",
      "metadata": {
        "id": "73751055"
      },
      "source": [
        "### Step 3: Encode Sequences and Format DataFrames\n",
        "    (a) Create codes to encode emission and hidden sequences\n",
        "    (b) Apply encodings & specify hidden sequence of interest (q2, q3, q8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bade82aa",
      "metadata": {
        "id": "bade82aa",
        "outputId": "94900c36-a921-49c0-d1e9-ece7775bf975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "emission_code:\n",
            "A:0 R:1 N:2 D:3 C:4 E:5 Q:6 G:7 H:8 I:9 L:10 K:11 M:12 F:13 P:14 S:15 T:16 W:17 Y:18 V:19 X:20 $:21 \n",
            "\n",
            "state_code:\n",
            "H:0 C:1 E:2 "
          ]
        }
      ],
      "source": [
        "emission_code = {residue_list[i]:i for i in range(len(residue_list)-1)}\n",
        "emission_code['$'] = 21\n",
        "state_code = {q3_list[i]:i for i in range(len(q3_list)-1)}\n",
        "\n",
        "print(\"emission_code:\")\n",
        "for k,v in emission_code.items():\n",
        "    print(f\"{k}:{v}\", end=\" \")\n",
        "\n",
        "print(\"\\n\\nstate_code:\")\n",
        "for k,v in state_code.items():\n",
        "    print(f\"{k}:{v}\", end=\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f86c13d",
      "metadata": {
        "id": "0f86c13d",
        "outputId": "c09ddfaf-0304-4676-f6ff-2adafb1cdece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding sequences\n"
          ]
        }
      ],
      "source": [
        "print(\"Encoding sequences\")\n",
        "gap = 4\n",
        "\n",
        "train_df_formatted = format_dataset(train_df, emission_code, state_code, 'q3_expected')\n",
        "dev_df_formatted = format_dataset(dev_df, emission_code, state_code, 'q3_expected')\n",
        "test_df_formatted = format_dataset(test_df, emission_code, state_code, 'q3_expected')   \n",
        "\n",
        "#make a copy and encode context\n",
        "train_df_context = train_df_formatted\n",
        "dev_df_context = dev_df_formatted\n",
        "test_df_context = test_df_formatted\n",
        "\n",
        "#give start vals\n",
        "\n",
        "#Tell it how far to look back\n",
        "\n",
        "\n",
        "#pad beginning by '$' start symbols determined by lookback length\n",
        "train_df_context['input'] = train_df_context['input'].apply(lambda x : [21 for i in range(gap-1)] + x)\n",
        "dev_df_context['input'] = dev_df_context['input'].apply(lambda x : [21 for i in range(gap-1)] + x)\n",
        "test_df_context['input'] = test_df_context['input'].apply(lambda x : [21 for i in range(gap-1)] + x)\n",
        "\n",
        "#encodes context and truncates expected vals\n",
        "\n",
        "train_df_context['input'] = train_df_context['input'].apply(lambda x : encode_seq_context(x,gap))\n",
        "dev_df_context['input'] = dev_df_context['input'].apply(lambda x : encode_seq_context(x,gap))\n",
        "test_df_context['input'] = test_df_context['input'].apply(lambda x : encode_seq_context(x,gap))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "314938f7",
      "metadata": {
        "id": "314938f7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdcca29e",
      "metadata": {
        "id": "cdcca29e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15775fef",
      "metadata": {
        "id": "15775fef"
      },
      "source": [
        "### Step 4: Estimate HMM=(T, E, pi) using Our Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7f85bf8",
      "metadata": {
        "id": "f7f85bf8",
        "outputId": "210a99c0-2d57-47d7-af60-7a86d608f9e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing initial estimates for transition and emission matrices using training data\n",
            "Time to estimate T, E, pi is approx: 0.0 minutes\n"
          ]
        }
      ],
      "source": [
        "print(\"Computing initial estimates for transition and emission matrices using training data\")\n",
        "start = time.time()\n",
        "T = estimate_transition_matrix(train_df_context, state_code)\n",
        "E = estimate_emission_matrix(train_df_context, state_code, emission_code)\n",
        "pi = start_distribution(train_df_context,state_code)\n",
        "end = time.time()\n",
        "print(f\"Time to estimate T, E, pi is approx: {round((end-start)//60,4)} minutes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cd4e5c5",
      "metadata": {
        "id": "4cd4e5c5"
      },
      "source": [
        "### Step 5: Compare HMM against Prior Research [5]\n",
        "\n",
        "    Some slight difference is expected because they were only able to train and test on CB531 whereas we will be training on CB6113 and testing on CB531.\n",
        "\n",
        "    [5] W. Ding, D. Dai, J. Xie, H. Zhang, W. Zhang and H. Xie, \"PRT-HMM: A Novel Hidden Markov Model for Protein Secondary Structure Prediction,\" 2012 IEEE/ACIS 11th International Conference on Computer and Information Science, 2012, pp. 207-212, doi: 10.1109/ICIS.2012.89.\n",
        "\n",
        "    https://ieeexplore-ieee-org.ezproxy.cul.columbia.edu/stamp/stamp.jsp?tp=&arnumber=6211098\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b13f3b4",
      "metadata": {
        "id": "2b13f3b4",
        "outputId": "ca946c07-841c-4da7-c372-43e3d430f541"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start Distribution (H,C,E) x (H,C,E):\n",
            "[0.3844 0.3973 0.2183]\n"
          ]
        }
      ],
      "source": [
        "print(\"Start Distribution (H,C,E) x (H,C,E):\")\n",
        "print(pi.round(decimals=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a399c5ab",
      "metadata": {
        "id": "a399c5ab",
        "outputId": "e0f79aa6-709f-42a6-9219-2b419c80d495"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.0348, -0.0432,  0.0083])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#compare start distribution to source\n",
        "pi_source = np.array([0.3496, 0.4405, 0.2100] )\n",
        "pi_delta = (pi - pi_source).round(decimals=4)\n",
        "pi_delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99c3940f",
      "metadata": {
        "id": "99c3940f",
        "outputId": "c7cdac64-9bdf-4d50-d0cd-d3916b4a09db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transition Matrix (H,C,E) x (H,C,E):\n",
            "[[0.899  0.0982 0.0028]\n",
            " [0.0937 0.8083 0.098 ]\n",
            " [0.0093 0.172  0.8187]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Transition Matrix (H,C,E) x (H,C,E):\")\n",
        "print(T.round(decimals=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "654347a2",
      "metadata": {
        "id": "654347a2",
        "outputId": "907f069a-2a14-4ce2-b35b-62495cf1742d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.0053, -0.0054,  0.0001],\n",
              "       [ 0.0127, -0.0214,  0.0087],\n",
              "       [ 0.0002, -0.0081,  0.0079]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#compare transition matrix to source\n",
        "T_source = np.array( \\\n",
        "    [[0.8937, 0.1036, 0.0027], \\\n",
        "     [0.0810, 0.8297, 0.0893], \\\n",
        "     [0.0091, 0.1801, 0.8108 ]]\n",
        "    )\n",
        "\n",
        "T_delta = (T - T_source).round(decimals=4)\n",
        "T_delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ace595f9",
      "metadata": {
        "id": "ace595f9",
        "outputId": "c4f54db2-8971-4007-b089-ef7f36d83b12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Emissions Matrix (H,C,E) x (H,C,E):\n",
            "[[[1.244e-01 1.190e-02 8.400e-02 ... 3.400e-02 8.500e-03 0.000e+00]\n",
            "  [9.980e-02 1.670e-02 8.420e-02 ... 3.410e-02 5.800e-03 2.000e-04]\n",
            "  [1.124e-01 1.230e-02 7.880e-02 ... 4.200e-02 9.000e-03 0.000e+00]\n",
            "  ...\n",
            "  [1.068e-01 9.600e-03 9.570e-02 ... 3.980e-02 7.200e-03 1.000e-04]\n",
            "  [1.104e-01 8.600e-03 9.520e-02 ... 3.310e-02 2.620e-02 3.000e-04]\n",
            "  [8.880e-02 7.700e-03 1.374e-01 ... 2.170e-02 1.430e-02 3.000e-04]]\n",
            "\n",
            " [[7.300e-02 1.050e-02 5.660e-02 ... 2.700e-02 5.400e-03 0.000e+00]\n",
            "  [6.160e-02 2.690e-02 6.150e-02 ... 2.970e-02 4.400e-03 2.000e-04]\n",
            "  [6.030e-02 1.010e-02 6.310e-02 ... 3.100e-02 4.900e-03 0.000e+00]\n",
            "  ...\n",
            "  [5.890e-02 1.040e-02 6.140e-02 ... 3.250e-02 4.600e-03 1.000e-04]\n",
            "  [5.230e-02 9.800e-03 6.050e-02 ... 3.500e-02 2.220e-02 4.000e-04]\n",
            "  [6.260e-02 1.150e-02 5.060e-02 ... 2.930e-02 2.100e-02 1.000e-04]]\n",
            "\n",
            " [[6.960e-02 1.600e-02 4.830e-02 ... 4.040e-02 6.600e-03 1.000e-04]\n",
            "  [5.980e-02 2.990e-02 4.680e-02 ... 4.290e-02 6.500e-03 4.000e-04]\n",
            "  [6.280e-02 1.620e-02 4.890e-02 ... 4.770e-02 6.800e-03 1.000e-04]\n",
            "  ...\n",
            "  [5.950e-02 1.670e-02 4.820e-02 ... 5.130e-02 6.200e-03 1.000e-04]\n",
            "  [7.640e-02 1.730e-02 6.340e-02 ... 4.400e-02 1.870e-02 7.000e-04]\n",
            "  [5.620e-02 1.380e-02 3.980e-02 ... 4.460e-02 5.800e-03 3.000e-04]]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Emissions Matrix (H,C,E) x (H,C,E):\")\n",
        "print(E.round(decimals=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "358ddf4c",
      "metadata": {
        "id": "358ddf4c"
      },
      "source": [
        "# Can no longer compare for context sensitive changed to markdown\n",
        "\n",
        "#compare emission matrix to source\n",
        "E_source = np.array( \\\n",
        "    [[0.1218, 0.0686, 0.0664], \\\n",
        "    [0.0563, 0.0406, 0.0414], \\\n",
        "    [0.0365, 0.0626, 0.0278], \\\n",
        "    [0.0531, 0.0787, 0.0315], \\\n",
        "    [0.0126, 0.0166, 0.0220], \\\n",
        "    [0.0855, 0.0502, 0.0418], \\\n",
        "    [0.0500, 0.0321, 0.0279], \\\n",
        "    [0.0372, 0.1239, 0.0528], \\\n",
        "    [0.0196, 0.0242, 0.0226], \\\n",
        "    [0.0548, 0.0353, 0.0966], \\\n",
        "    [0.1116, 0.0603, 0.1003], \\\n",
        "    [0.0679, 0.0578, 0.0472], \\\n",
        "    [0.0263, 0.0152, 0.0215], \\\n",
        "    [0.0391, 0.0318, 0.0537], \\\n",
        "    [0.0244, 0.0775, 0.0192], \\\n",
        "    [0.0492, 0.0737, 0.0543], \\\n",
        "    [0.0433, 0.0636, 0.0743], \\\n",
        "    [0.0153, 0.0113, 0.0187], \\\n",
        "    [0.0353, 0.0292, 0.0485], \\\n",
        "    [0.0603, 0.0469, 0.1315]]\n",
        "    )\n",
        "\n",
        "#source does not have emission for X amino acid label\n",
        "E_delta = (E[:,:-1] - E_source.T).round(decimals=4)\n",
        "E_delta"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1b19f87",
      "metadata": {
        "id": "c1b19f87"
      },
      "source": [
        "### Step 6: Compute HMM Prediction Performance on Train Data\n",
        "\n",
        "---\n",
        "\n",
        "    and compare against performance of traditional HMM from [5] as sanity check:\n",
        "        Overall Accuracy: 44.38%\n",
        "        Helix Accuracy (H): 90.46%\n",
        "        Beta-Sheet Accuracy (E): 4.56%\n",
        "        Coil Accuracy (C): 28.05%\n",
        "        \n",
        "     *Some slight difference is expected because they were only able to train and test on CB531 whereas we will be training on CB6113 and testing on CB531.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15c97cdc",
      "metadata": {
        "id": "15c97cdc",
        "outputId": "c24400b8-547f-4913-b11f-c54b3584ed87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time predict on training data is approx: 14.11 seconds\n"
          ]
        }
      ],
      "source": [
        "#make predictions\n",
        "start = time.time()\n",
        "train_predictions = getPredictions(train_df_context, T, E, pi)\n",
        "train_acc, train_prec, train_rec, train_cnts = HMMaccuracy(train_predictions, q=3)\n",
        "end = time.time()\n",
        "print(f\"Time predict on training data is approx: {round((end-start),2)} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d544fadd",
      "metadata": {
        "id": "d544fadd",
        "outputId": "2c4c04f4-9de9-4b72-eda4-62c04e04bcb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.4778 \n",
            "\n",
            "Precision (H,C,E):\n",
            "\t [0.4502 0.6167 0.4053] \n",
            "\n",
            "Recall (H,C,E):\n",
            "\t [0.9077 0.278  0.0803] \n",
            "\n",
            "Counts (H,C,E) x (H,C,E):\n",
            "[[363738  26624  10373]\n",
            " [279126 113800  16435]\n",
            " [165143  44118  18268]]\n"
          ]
        }
      ],
      "source": [
        "#Our HMM performance\n",
        "\n",
        "print(f\"Accuracy: {round(train_acc,4)} \\n\")\n",
        "print(f\"Precision (H,C,E):\\n\\t {train_prec.round(decimals = 4)} \\n\")\n",
        "print(f\"Recall (H,C,E):\\n\\t {train_rec.round(decimals = 4)} \\n\")\n",
        "print(\"Counts (H,C,E) x (H,C,E):\")\n",
        "print(train_cnts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "334414bf",
      "metadata": {
        "id": "334414bf"
      },
      "source": [
        "### Step 7: Compute HMM Performance on Dev Data\n",
        "\n",
        "    and compare against performance of traditional HMM from [5] as sanity check:\n",
        "            Overall Accuracy: 44.38%\n",
        "            Helix Accuracy (H): 90.46%\n",
        "            Beta-Sheet Accuracy (E): 4.56%\n",
        "            Coil Accuracy (C): 28.05%\n",
        "        \n",
        "     *Some slight difference is expected because they were only able to train and test on CB531 whereas we will be training on CB6113 and testing on CB531."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09ec68c6",
      "metadata": {
        "id": "09ec68c6",
        "outputId": "a7152207-c423-46d4-b0b3-17c3a7e81df8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time predict on dev data is approx: 1.56 seconds\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "dev_predictions = getPredictions(dev_df_context, T, E, pi)\n",
        "dev_acc, dev_prec, dev_rec, dev_cnts = HMMaccuracy(dev_predictions, q=3)\n",
        "end = time.time()\n",
        "print(f\"Time predict on dev data is approx: {round((end-start),2)} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a639b81d",
      "metadata": {
        "id": "a639b81d",
        "outputId": "8ae8ee42-8bc7-42f7-a852-6b27342165cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.4904 \n",
            "\n",
            "Precision (H,C,E):\n",
            "\t [0.4645 0.6167 0.4393] \n",
            "\n",
            "Recall (H,C,E):\n",
            "\t [0.9154 0.2771 0.0774] \n",
            "\n",
            "Counts (H,C,E) x (H,C,E):\n",
            "[[40747  2998   766]\n",
            " [30010 12093  1533]\n",
            " [16956  4518  1801]]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy: {round(dev_acc,4)} \\n\")\n",
        "print(f\"Precision (H,C,E):\\n\\t {dev_prec.round(decimals = 4)} \\n\")\n",
        "print(f\"Recall (H,C,E):\\n\\t {dev_rec.round(decimals = 4)} \\n\")\n",
        "print(\"Counts (H,C,E) x (H,C,E):\")\n",
        "print(dev_cnts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68dfff14",
      "metadata": {
        "id": "68dfff14"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "name": "CS HMM.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}