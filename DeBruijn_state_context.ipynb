{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8826fad",
      "metadata": {
        "id": "c8826fad"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from itertools import product\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dc9eb20",
      "metadata": {
        "id": "5dc9eb20"
      },
      "outputs": [],
      "source": [
        "def get_data(arr, residue_list, q8_list, columns, r, f, bounds=None):\n",
        "    \n",
        "    \"\"\"\n",
        "    This function retrieves and formats data from the CB6133_filtered and CB531 datasets [1][2]\n",
        "    Codes is slighlty modified from code provided by [3][4]\n",
        "    \n",
        "    [1] Jian Zhou and Olga G. Troyanskaya. Deep supervised and convolutional generative stochastic network for\n",
        "        protein s\n",
        "    [2] Jian Zhou and Olga G. Troyanskaya. CB6133 dataset.\n",
        "        https://www.princeton.edu/~jzthree/datasets/ICML2014/dataset_readme.txt, 2014.\n",
        "    [3] Iddo Drori et al. High Quality Prediction of Protein Q8 Secondary Structure by\n",
        "        Diverse Neural Network Architectures. arXiv preprint arXiv:1811.07143, 2018\n",
        "    [4] https://github.com/idrori/cu-ssp/blob/master/model_1/model_1.py\n",
        "    \"\"\"\n",
        "    \n",
        "    if bounds is None: bounds = range(len(arr))\n",
        "    \n",
        "    data = [None for i in bounds]\n",
        "    for i in bounds:\n",
        "        seq, q8, q3, q2, profiles = '', '', '', '', []\n",
        "        for j in range(r):\n",
        "            jf = j*f\n",
        "            \n",
        "            # Residue convert from one-hot to decoded\n",
        "            residue_onehot = arr[i,jf+0:jf+22]\n",
        "            residue = residue_list[np.argmax(residue_onehot)]\n",
        "\n",
        "            # Q8 one-hot encoded to decoded structure symbol\n",
        "            residue_q8_onehot = arr[i,jf+22:jf+31]\n",
        "            residue_q8 = q8_list[np.argmax(residue_q8_onehot)]\n",
        "\n",
        "            if residue == 'NoSeq': break      # terminating sequence symbol\n",
        "\n",
        "            nc_terminals = arr[i,jf+31:jf+33] # nc_terminals = [0. 0.]\n",
        "            sa = arr[i,jf+33:jf+35]           # sa = [0. 0.]\n",
        "            profile = arr[i,jf+35:jf+57]      # profile features\n",
        "            \n",
        "            seq += residue # concat residues into amino acid sequence\n",
        "\n",
        "            #encode q3 structure\n",
        "            if residue_q8 in 'GHI':\n",
        "                q3 += 'H'\n",
        "                q2 += 'A'\n",
        "            elif residue_q8 in 'E':\n",
        "                q3 += 'E'\n",
        "                q2 += 'X'\n",
        "            else:\n",
        "                q3 += 'C'\n",
        "                q2 += 'X'\n",
        "            \n",
        "            q8  += residue_q8 # concat secondary structure into secondary structure sequence\n",
        "            profiles.append(profile)\n",
        "        \n",
        "        data[i] = [str(i+1), len(seq), seq, np.array(profiles), q8, q3, q2]\n",
        "    \n",
        "    return pd.DataFrame(data, columns=columns)\n",
        "\n",
        "\n",
        "def create_context_code(symbols, context):\n",
        "    \n",
        "    context_encode = {}\n",
        "    context_decode = {}\n",
        "    \n",
        "    i=0\n",
        "    for comb in product(symbols, repeat=context):\n",
        "        \n",
        "        x = ''.join(comb)\n",
        "        context_encode[x] = i\n",
        "        context_decode[i] = x\n",
        "        \n",
        "        i += 1\n",
        "        \n",
        "    \n",
        "    for j in range(1,context):\n",
        "        for comb in product(symbols, repeat=(context-j)):\n",
        "            x = '$'*j + ''.join(comb)\n",
        "            context_encode[x] = i\n",
        "            context_decode[i] = x\n",
        "\n",
        "            i += 1\n",
        "    \n",
        "    return context_encode, context_decode\n",
        "    \n",
        "\n",
        "def encode_sequence(sequence, code, context):\n",
        "    \n",
        "    \"\"\"\n",
        "    Provided an input sequence and a code, returns the encoding of the sequence\n",
        "    \"\"\"\n",
        "    \n",
        "    encoded_seq = []\n",
        "    \n",
        "    if context > 1:\n",
        "        seq = '$' * (context-1)\n",
        "        seq = seq + sequence\n",
        "    else:\n",
        "        seq = sequence\n",
        "        \n",
        "    for i in range(context, len(seq)+1):\n",
        "        \n",
        "        x = seq[i-context:i]\n",
        "    \n",
        "        try:\n",
        "            idx = code[x]\n",
        "            encoded_seq.append(idx)\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            break\n",
        "    \n",
        "    assert len(encoded_seq) == len(sequence)\n",
        "    \n",
        "    return encoded_seq\n",
        "\n",
        "\n",
        "def decode_sequence(sequence, code):\n",
        "    \n",
        "    decoded_seq = ''\n",
        "    \n",
        "    for i in range(len(sequence)):\n",
        "        \n",
        "        x = sequence[i]\n",
        "        x = code[x]\n",
        "        \n",
        "        decoded_seq += x[-1]\n",
        "        \n",
        "    \n",
        "    return decoded_seq\n",
        "        \n",
        "\n",
        "def format_dataset(df, emission_code, state_code, emission_context, state_context, exp_col=\"q3_expected\"):\n",
        "    \n",
        "    \"\"\"\n",
        "    Provided a dataframe which contains the amino sequences and the hidden sequence,\n",
        "    this function encodes those sequences according to the provided codes\n",
        "    and return them\n",
        "    \n",
        "    *exp_col specifies if want to encode the q8, q3, or q2 hidden sequence\n",
        "    \"\"\"\n",
        "    \n",
        "    assert ('id' in df.columns and 'len' in df.columns and 'input' in df.columns and exp_col in df.columns)\n",
        "    \n",
        "    formattedDF = pd.DataFrame(columns=['id','len','input','expected'])\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        \n",
        "        sid = df.iloc[i].id\n",
        "        enc_input = encode_sequence(df.iloc[i].input, emission_code, emission_context)\n",
        "        enc_expected = encode_sequence(df.iloc[i][exp_col], state_code, state_context)\n",
        "        \n",
        "        assert (len(enc_input) == len(enc_expected))\n",
        "        \n",
        "        formattedDF = formattedDF.append({'id':sid, 'input':enc_input, 'expected':enc_expected}, ignore_index=True)\n",
        "\n",
        "    return formattedDF\n",
        "\n",
        "def estimate_transition_matrix(df, state_code, possible_priors):\n",
        "    \"\"\"\n",
        "    Given a dataframe that has the data for the amino sequences and their corresponding hidden sequence,\n",
        "    we use the data to compute the MLEs of the emission probablities.\n",
        "    \n",
        "    ex. estimated P(emission=A|state=H) = count(emission=A,state=H) / sum_over_all_emission count(emission, state=H)\n",
        "    \n",
        "    *implemented a pseudocount of +1 for cases where we have 0 observations of a certain (emission,state) combo\n",
        "    \"\"\"\n",
        "    \n",
        "    n_states = len(state_code)\n",
        "    \n",
        "    counts = np.zeros(shape=(n_states, n_states), dtype=int)\n",
        "    \n",
        "    #using pseudocount of +1 for only those transitions that are actually possible\n",
        "    for y, priors in possible_priors.items():\n",
        "        for x in priors:\n",
        "            counts[x,y] += 1\n",
        "    \n",
        "    for i in range(len(df)):\n",
        "        \n",
        "        state_seq = df.iloc[i].expected\n",
        "        seq_len = len(state_seq)\n",
        "        \n",
        "        for j in range(seq_len - 1):\n",
        "            \n",
        "            x = state_seq[j]\n",
        "            y = state_seq[j+1]\n",
        "            \n",
        "            counts[x,y] += 1\n",
        "    \n",
        "    #transform counts to probability by normalizing of row sums\n",
        "    row_sums = np.sum(counts, axis=1)\n",
        "    T = counts / row_sums.reshape((-1,1))\n",
        "    \n",
        "    return T\n",
        "\n",
        "\n",
        "def estimate_emission_matrix(df, state_code, emission_code):\n",
        "    \"\"\"\n",
        "    Given a dataframe that has the data for the amino sequences and their corresponding hidden sequence,\n",
        "    we use the data to compute the MLEs of the transition probablities.\n",
        "    \n",
        "    ex. estimated P(state_{t+1}=E|state_{t}=H) = count(state_{t}=H, state_{t+1}=E) / sum_over_all_states count(state_{t}=H, state_{t+1})\n",
        "    \n",
        "    *implemented a pseudocount of +1 for cases where we have 0 observations of a certain (state,state) combo\n",
        "    \"\"\"\n",
        "    \n",
        "    n_states = len(state_code)\n",
        "    n_emissions = len(emission_code)\n",
        "    \n",
        "    #using pseudocount of +1\n",
        "    counts = np.ones(shape=(n_states, n_emissions), dtype=int)\n",
        "    \n",
        "    for i in range(len(df)):\n",
        "        \n",
        "        state_seq = df.iloc[i].expected\n",
        "        emission_seq = df.iloc[i].input\n",
        "        seq_len = len(emission_seq)\n",
        "        \n",
        "        for j in range(seq_len):\n",
        "            \n",
        "            x = state_seq[j]\n",
        "            y = emission_seq[j]\n",
        "            \n",
        "            try:\n",
        "                counts[x,y] += 1\n",
        "            except:\n",
        "                print(x,y)\n",
        "\n",
        "    #transform counts to probability by normalizing of row sums\n",
        "    row_sums = np.sum(counts, axis=1)\n",
        "    E = counts / row_sums.reshape((-1,1))\n",
        "    \n",
        "    return E\n",
        "\n",
        "def start_distribution(df, state_symbols, state_decode):\n",
        "    \"\"\"\n",
        "    Given a dataframe that has the data for the amino sequences and their corresponding hidden sequence,\n",
        "    we use the data to compute the MLEs of the start distribution.\n",
        "    \n",
        "    ex. estimated P(state=H) = count(state=H) / sum_over_all_states count(state)\n",
        "    \n",
        "    *implemented a pseudocount of +1 for cases where we have 0 observations of a certain state\n",
        "    \"\"\"\n",
        "    \n",
        "    n_states = len(state_symbols)\n",
        "    \n",
        "    #using pseudocount of +1\n",
        "    counts = np.array([1.0] * n_states)\n",
        "    \n",
        "    for i in range(len(df)):\n",
        "        \n",
        "        state_seq = df.iloc[i].expected\n",
        "        seq_len = len(state_seq)\n",
        "        \n",
        "        for j in range(seq_len):\n",
        "            \n",
        "            x = state_seq[j]\n",
        "            x = state_decode[x][-1]\n",
        "            idx = state_symbols[x]\n",
        "            \n",
        "            counts[idx] += 1\n",
        "    \n",
        "    #transform counts to probability by normalizing of row sums\n",
        "    total = sum(counts)\n",
        "    pi = counts / total\n",
        "    \n",
        "    return pi\n",
        "\n",
        "def viterbi_decoding(T,E,pi,seq,state_symbols, state_decode, possible_priors):\n",
        "    \"\"\"\n",
        "    This functions performs viterbi decoding to get the predicted hidden sequence,\n",
        "    given the input emission sequence as well as the transition matrix, emission matrix,\n",
        "    and the start distribution\n",
        "    \"\"\"\n",
        "    \n",
        "    #sequence length\n",
        "    N = len(seq)\n",
        "    #num of states\n",
        "    M = T.shape[0]\n",
        "    \n",
        "    assert (M == len(state_decode) and len(pi) == len(state_symbols))\n",
        "    \n",
        "    #V will store viterbi values\n",
        "    V = np.zeros(shape=(M, N), dtype=float)\n",
        "    \n",
        "    #P will store prev state from which we transitioned into state m and time n to achieve the max value of V[m,n]\n",
        "    #(i.e. pointer to help us reconstruct sequence after predicting most probable path in viterbi graph)\n",
        "    P = np.empty(shape=(M, N))\n",
        "    P[:] = np.NaN\n",
        "    \n",
        "    #populate viterbi matrix\n",
        "    for n in range(N):\n",
        "        \n",
        "        #get current emissions\n",
        "        e = seq[n]\n",
        "        \n",
        "        for m in range(M):\n",
        "            \n",
        "            #initilize viterbi value for current timestep given state m to be -infty\n",
        "            maxV = float(\"-inf\")\n",
        "            prev = np.NaN\n",
        "            \n",
        "            #get log prob. of emission given state m\n",
        "            emiss_logp = np.log(E[m,e])\n",
        "            \n",
        "            #start of sequence\n",
        "            if n == 0:\n",
        "                \n",
        "                sym = state_decode[m][-1]\n",
        "                sym_idx = state_symbols[sym]\n",
        "                start_logp = np.log(pi[sym_idx])\n",
        "                maxV = emiss_logp + start_logp\n",
        "                \n",
        "            else:\n",
        "            \n",
        "                #solve for max value for V[m,n]\n",
        "                for i in possible_priors[m]: \n",
        "\n",
        "                    #get previous timestep viterbi value for state i (which should be a log prob)\n",
        "                    prev_vit = V[i, n-1]\n",
        "\n",
        "                    #get log prob of transition from state i to m\n",
        "                    trans_logp = np.log(T[i,m])\n",
        "\n",
        "                    #update viterbi value for current timestep given state m\n",
        "                    curV = prev_vit + trans_logp + emiss_logp\n",
        "\n",
        "                    if curV > maxV:\n",
        "                        maxV = curV\n",
        "                        prev = i\n",
        "        \n",
        "            V[m,n] = maxV\n",
        "            P[m,n] = prev\n",
        "    \n",
        "    #initialize with state with highest probability at end of sequence\n",
        "    best_path = [np.argmax(V[:,-1])]\n",
        "    \n",
        "    #work backwards to reconstruct sequence\n",
        "    for n in range(N-1,0,-1):\n",
        "        \n",
        "        #determine where we are\n",
        "        cur_state = best_path[0]\n",
        "\n",
        "        #find state from which we came that yielded highest probability to current state at current time\n",
        "        prev_state = int(P[cur_state,n])\n",
        "\n",
        "        #prepend previous state\n",
        "        best_path = [prev_state] + best_path\n",
        "    \n",
        "    return best_path\n",
        "\n",
        "\n",
        "def getPredictions(df, T, E, pi, state_symbols, state_decode, possible_priors):\n",
        "    \n",
        "    \"\"\"\n",
        "    get predictions for all sequences in specified dataset using provided HMM\n",
        "    \"\"\"\n",
        "    \n",
        "    results = pd.DataFrame(columns=['input','predicted','expected'])\n",
        "    \n",
        "    for i in tqdm(range(len(df)), desc=\"Decoding sequences\"):\n",
        "        \n",
        "        amino_seq = df.iloc[i].input\n",
        "        pred_seq = viterbi_decoding(T,E,pi,amino_seq,state_symbols, state_decode, possible_priors)\n",
        "        exp_seq = df.iloc[i].expected\n",
        "        \n",
        "        assert(len(amino_seq) == len(pred_seq) and len(amino_seq) == len(exp_seq))\n",
        "        \n",
        "        results = results.append({'input':amino_seq, 'predicted':pred_seq, 'expected':exp_seq}, ignore_index=True)\n",
        "    \n",
        "    return results\n",
        "\n",
        "def HMMaccuracy(df,state_decode, state_symbols):\n",
        "    \n",
        "    \"\"\"\n",
        "    Compute accurcay of HMM given a dataframe the has the input emission sequences,\n",
        "    the predicted hidden sequences, and the actual hidden sequences\n",
        "    \n",
        "    *q specifies whether the predicion was made for q2, q3, or q8 protein structure\n",
        "    \"\"\"\n",
        "    \n",
        "    #row represents expected state\n",
        "    #col represents predicted state\n",
        "    q = len(state_symbols)\n",
        "    counts = np.zeros(shape=(q,q), dtype=int)\n",
        "    \n",
        "    for i in range(len(df)):\n",
        "\n",
        "        #get predicted and expected hidden sequence from dataframe\n",
        "        pred = df.iloc[i].predicted\n",
        "        pred = decode_sequence(pred, state_decode)\n",
        "        exp = df.iloc[i].expected\n",
        "        exp = decode_sequence(exp, state_decode)\n",
        "        \n",
        "        assert (len(pred) == len(exp))\n",
        "        \n",
        "        for j in range(len(pred)):\n",
        "            \n",
        "            x = state_symbols[exp[j]]\n",
        "            y = state_symbols[pred[j]]\n",
        "            counts[x,y] += 1\n",
        "    \n",
        "    rowSum = np.sum(counts, axis=1)\n",
        "    colSum = np.sum(counts, axis=0)\n",
        "    \n",
        "    #true positive (negative) / total predicted positive (negative)\n",
        "    precision = np.array([counts[i,i] / colSum[i] for i in range(q)])\n",
        "    \n",
        "    #true positive (negative) / total actual positive (negative)\n",
        "    recall = np.array([counts[i,i] / rowSum[i] for i in range(q)])\n",
        "    \n",
        "    accuracy = 0\n",
        "    for i in range(q):\n",
        "        accuracy += counts[i,i]\n",
        "    accuracy = accuracy / sum(rowSum)\n",
        "    \n",
        "    \n",
        "    return accuracy, precision, recall, counts\n",
        "       \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cb7d176",
      "metadata": {
        "id": "0cb7d176"
      },
      "source": [
        "### Step 1: Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e728564",
      "metadata": {
        "id": "1e728564",
        "outputId": "4bd353ae-3495-4b80-fa70-c277ce1d0d9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5f2a3c87eb29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcb513\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cb513+profile_split1.npy.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcb6133filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cullpdb+profile_5926_filtered.npy.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data Loaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cb513+profile_split1.npy.gz'"
          ]
        }
      ],
      "source": [
        "#seed so get consistent results for every run\n",
        "random.seed(0)\n",
        "\n",
        "cb513 = np.load('cb513+profile_split1.npy.gz')\n",
        "cb6133filtered = np.load('cullpdb+profile_5926_filtered.npy.gz')\n",
        "print(\"Data Loaded\")\n",
        "print(f\"CB6133 shape: {cb6133filtered.shape}\")\n",
        "print(f\"CB513 shape: {cb513.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa08e5a6",
      "metadata": {
        "id": "fa08e5a6"
      },
      "source": [
        "### Step 2: Process Data\n",
        "    & split into train, dev, and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7d278e9",
      "metadata": {
        "id": "f7d278e9",
        "outputId": "d59ac4f5-aaa3-40cd-e3fc-62447223d4bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Turning data arrays into dataframes\n"
          ]
        }
      ],
      "source": [
        "maxlen_seq = r = 700 # protein residues padded to 700\n",
        "f = 57  # number of features for each residue\n",
        "\n",
        "residue_list = list('ACEDGFIHKMLNQPSRTWVYX') + ['NoSeq']\n",
        "q8_list      = list('LBEGIHST') + ['NoSeq']\n",
        "q3_list      = list('HCE') + ['NoSeq']\n",
        "q2_list      = list('AX') + ['NoSeq']\n",
        "\n",
        "columns = [\"id\", \"len\", \"input\", \"profiles\", \"q8_expected\", \"q3_expected\", \"q2_expected\"]\n",
        "\n",
        "print(\"Turning data arrays into dataframes\")\n",
        "\n",
        "# train, dev, test split\n",
        "# break out 10% of train data to be used as dev set\n",
        "train_df, dev_df = train_test_split(get_data(cb6133filtered, residue_list, q8_list, columns, r, f), test_size=0.1, random_state=11)\n",
        "test_df  = get_data(cb513, residue_list, q8_list, columns, r, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "054246a3",
      "metadata": {
        "id": "054246a3"
      },
      "source": [
        "### Step 3: Encode Sequences and Format DataFrames\n",
        "    (a) Create codes to encode emission and hidden sequences\n",
        "    (b) Apply encodings & specify hidden sequence of interest (q2, q3, q8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "816801ee",
      "metadata": {
        "id": "816801ee",
        "outputId": "2c1ac595-88d1-4054-8a07-0d6e3a367a80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "emission_code:\n",
            "A:0 C:1 E:2 D:3 G:4 F:5 I:6 H:7 K:8 M:9 L:10 N:11 Q:12 P:13 S:14 R:15 T:16 W:17 V:18 Y:19 X:20 \n",
            "\n",
            "state_code:\n",
            "HHHH:0 HHHC:1 HHHE:2 HHCH:3 HHCC:4 HHCE:5 HHEH:6 HHEC:7 HHEE:8 HCHH:9 HCHC:10 HCHE:11 HCCH:12 HCCC:13 HCCE:14 HCEH:15 HCEC:16 HCEE:17 HEHH:18 HEHC:19 HEHE:20 HECH:21 HECC:22 HECE:23 HEEH:24 HEEC:25 HEEE:26 CHHH:27 CHHC:28 CHHE:29 CHCH:30 CHCC:31 CHCE:32 CHEH:33 CHEC:34 CHEE:35 CCHH:36 CCHC:37 CCHE:38 CCCH:39 CCCC:40 CCCE:41 CCEH:42 CCEC:43 CCEE:44 CEHH:45 CEHC:46 CEHE:47 CECH:48 CECC:49 CECE:50 CEEH:51 CEEC:52 CEEE:53 EHHH:54 EHHC:55 EHHE:56 EHCH:57 EHCC:58 EHCE:59 EHEH:60 EHEC:61 EHEE:62 ECHH:63 ECHC:64 ECHE:65 ECCH:66 ECCC:67 ECCE:68 ECEH:69 ECEC:70 ECEE:71 EEHH:72 EEHC:73 EEHE:74 EECH:75 EECC:76 EECE:77 EEEH:78 EEEC:79 EEEE:80 $HHH:81 $HHC:82 $HHE:83 $HCH:84 $HCC:85 $HCE:86 $HEH:87 $HEC:88 $HEE:89 $CHH:90 $CHC:91 $CHE:92 $CCH:93 $CCC:94 $CCE:95 $CEH:96 $CEC:97 $CEE:98 $EHH:99 $EHC:100 $EHE:101 $ECH:102 $ECC:103 $ECE:104 $EEH:105 $EEC:106 $EEE:107 $$HH:108 $$HC:109 $$HE:110 $$CH:111 $$CC:112 $$CE:113 $$EH:114 $$EC:115 $$EE:116 $$$H:117 $$$C:118 $$$E:119 \n",
            "\n",
            "state_symbols:\n",
            "H:0 C:1 E:2 "
          ]
        }
      ],
      "source": [
        "emission_context = 1\n",
        "state_context = 4\n",
        "\n",
        "emission_encode, emission_decode = create_context_code(residue_list[:-1], emission_context)\n",
        "state_encode, state_decode = create_context_code(q3_list[:-1], state_context)\n",
        "\n",
        "state_symbols, _ = create_context_code(q3_list[:-1], 1)\n",
        "\n",
        "print(\"emission_code:\")\n",
        "for k,v in emission_encode.items():\n",
        "    print(f\"{k}:{v}\", end=\" \")\n",
        "\n",
        "print(\"\\n\\nstate_code:\")\n",
        "for k,v in state_encode.items():\n",
        "    print(f\"{k}:{v}\", end=\" \")\n",
        "    \n",
        "print(\"\\n\\nstate_symbols:\")\n",
        "for k,v in state_symbols.items():\n",
        "    print(f\"{k}:{v}\", end=\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1fc943d",
      "metadata": {
        "id": "a1fc943d",
        "outputId": "b702a15c-bfb9-45ce-b75b-f912e2c30be8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "defaultdict(<class 'list'>, {0: [0, 27, 54, 81], 1: [0, 27, 54, 81], 2: [0, 27, 54, 81], 3: [1, 28, 55, 82], 4: [1, 28, 55, 82], 5: [1, 28, 55, 82], 6: [2, 29, 56, 83], 7: [2, 29, 56, 83], 8: [2, 29, 56, 83], 9: [3, 30, 57, 84], 10: [3, 30, 57, 84], 11: [3, 30, 57, 84], 12: [4, 31, 58, 85], 13: [4, 31, 58, 85], 14: [4, 31, 58, 85], 15: [5, 32, 59, 86], 16: [5, 32, 59, 86], 17: [5, 32, 59, 86], 18: [6, 33, 60, 87], 19: [6, 33, 60, 87], 20: [6, 33, 60, 87], 21: [7, 34, 61, 88], 22: [7, 34, 61, 88], 23: [7, 34, 61, 88], 24: [8, 35, 62, 89], 25: [8, 35, 62, 89], 26: [8, 35, 62, 89], 27: [9, 36, 63, 90], 28: [9, 36, 63, 90], 29: [9, 36, 63, 90], 30: [10, 37, 64, 91], 31: [10, 37, 64, 91], 32: [10, 37, 64, 91], 33: [11, 38, 65, 92], 34: [11, 38, 65, 92], 35: [11, 38, 65, 92], 36: [12, 39, 66, 93], 37: [12, 39, 66, 93], 38: [12, 39, 66, 93], 39: [13, 40, 67, 94], 40: [13, 40, 67, 94], 41: [13, 40, 67, 94], 42: [14, 41, 68, 95], 43: [14, 41, 68, 95], 44: [14, 41, 68, 95], 45: [15, 42, 69, 96], 46: [15, 42, 69, 96], 47: [15, 42, 69, 96], 48: [16, 43, 70, 97], 49: [16, 43, 70, 97], 50: [16, 43, 70, 97], 51: [17, 44, 71, 98], 52: [17, 44, 71, 98], 53: [17, 44, 71, 98], 54: [18, 45, 72, 99], 55: [18, 45, 72, 99], 56: [18, 45, 72, 99], 57: [19, 46, 73, 100], 58: [19, 46, 73, 100], 59: [19, 46, 73, 100], 60: [20, 47, 74, 101], 61: [20, 47, 74, 101], 62: [20, 47, 74, 101], 63: [21, 48, 75, 102], 64: [21, 48, 75, 102], 65: [21, 48, 75, 102], 66: [22, 49, 76, 103], 67: [22, 49, 76, 103], 68: [22, 49, 76, 103], 69: [23, 50, 77, 104], 70: [23, 50, 77, 104], 71: [23, 50, 77, 104], 72: [24, 51, 78, 105], 73: [24, 51, 78, 105], 74: [24, 51, 78, 105], 75: [25, 52, 79, 106], 76: [25, 52, 79, 106], 77: [25, 52, 79, 106], 78: [26, 53, 80, 107], 79: [26, 53, 80, 107], 80: [26, 53, 80, 107], 81: [108], 82: [108], 83: [108], 84: [109], 85: [109], 86: [109], 87: [110], 88: [110], 89: [110], 90: [111], 91: [111], 92: [111], 93: [112], 94: [112], 95: [112], 96: [113], 97: [113], 98: [113], 99: [114], 100: [114], 101: [114], 102: [115], 103: [115], 104: [115], 105: [116], 106: [116], 107: [116], 108: [117], 109: [117], 110: [117], 111: [118], 112: [118], 113: [118], 114: [119], 115: [119], 116: [119]})\n"
          ]
        }
      ],
      "source": [
        "possible_priors = defaultdict(list)\n",
        "\n",
        "for key1, idx1 in state_encode.items():\n",
        "    for key2, idx2 in state_encode.items():\n",
        "        if key1[1:] == key2[0:-1]:\n",
        "            possible_priors[idx2].append(idx1)\n",
        "            \n",
        "print(possible_priors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e593699a",
      "metadata": {
        "id": "e593699a",
        "outputId": "ad55993d-f1ff-46dc-a9f3-5066686dc95f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding sequences\n"
          ]
        }
      ],
      "source": [
        "print(\"Encoding sequences\")\n",
        "train_df_formatted = format_dataset(train_df, emission_encode, state_encode, emission_context, state_context, 'q3_expected')\n",
        "dev_df_formatted = format_dataset(dev_df, emission_encode, state_encode, emission_context, state_context, 'q3_expected')\n",
        "test_df_formatted = format_dataset(test_df, emission_encode, state_encode, emission_context, state_context, 'q3_expected')  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfaf2584",
      "metadata": {
        "id": "dfaf2584"
      },
      "source": [
        "### Step 4: Estimate HMM=(T, E, pi) using Our Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbdb9135",
      "metadata": {
        "id": "cbdb9135",
        "outputId": "e6599b11-442c-4a2b-c6ee-2d35de2f624d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing initial estimates for transition and emission matrices using training data\n",
            "Time to estimate T, E, pi is approx: 0.0 minutes\n"
          ]
        }
      ],
      "source": [
        "print(\"Computing initial estimates for transition and emission matrices using training data\")\n",
        "start = time.time()\n",
        "T = estimate_transition_matrix(train_df_formatted, state_encode, possible_priors)\n",
        "E = estimate_emission_matrix(train_df_formatted, state_encode, emission_encode)\n",
        "pi = start_distribution(train_df_formatted,state_symbols, state_decode)\n",
        "end = time.time()\n",
        "print(f\"Time to estimate T, E, pi is approx: {round((end-start)//60,4)} minutes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "907d91af",
      "metadata": {
        "id": "907d91af"
      },
      "source": [
        "### Step 5: View HMM Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "440804a1",
      "metadata": {
        "id": "440804a1",
        "outputId": "8a628da6-95ac-4f48-ed5b-11f0559bbaa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start Distribution (H,C,E):\n",
            "[0.3863 0.3968 0.2169]\n"
          ]
        }
      ],
      "source": [
        "print(\"Start Distribution (H,C,E):\")\n",
        "print(pi.round(decimals=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa571f0a",
      "metadata": {
        "id": "fa571f0a",
        "outputId": "8c049b7a-f7f5-4c2e-81fb-b172893459e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transition Matrix (state x state):\n",
            "(120, 120)\n",
            "[[0.8815 0.1171 0.0014 ... 0.     0.     0.    ]\n",
            " [0.     0.     0.     ... 0.     0.     0.    ]\n",
            " [0.     0.     0.     ... 0.     0.     0.    ]\n",
            " ...\n",
            " [0.     0.     0.     ... 0.     0.     0.    ]\n",
            " [0.     0.     0.     ... 0.     0.     0.    ]\n",
            " [0.     0.     0.     ... 0.     0.     0.    ]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Transition Matrix (state x state):\")\n",
        "print(T.shape)\n",
        "print(T.round(decimals=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "862aac31",
      "metadata": {
        "id": "862aac31",
        "outputId": "f1af0af5-4b07-4cbe-db3e-1f1ebc3edbcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Emissions Matrix (state x emission):\n",
            "(120, 21)\n",
            "[[0.122  0.0114 0.0792 ... 0.0651 0.0366 0.0083]\n",
            " [0.0887 0.014  0.0503 ... 0.0426 0.0364 0.0068]\n",
            " [0.0549 0.027  0.0113 ... 0.2031 0.0541 0.0078]\n",
            " ...\n",
            " [0.0476 0.0476 0.0476 ... 0.0476 0.0476 0.0476]\n",
            " [0.0945 0.0066 0.0518 ... 0.0326 0.0105 0.052 ]\n",
            " [0.0476 0.0476 0.0476 ... 0.0476 0.0476 0.0476]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Emissions Matrix (state x emission):\")\n",
        "print(E.shape)\n",
        "print(E.round(decimals=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edfb10e2",
      "metadata": {
        "id": "edfb10e2"
      },
      "source": [
        "### Step 6: Compute HMM Performance on Dev Data\n",
        "\n",
        "    Accuracy: 0.445 \n",
        "\n",
        "    Precision (H,C,E):\n",
        "         [0.421  0.6171 0.4561] \n",
        "\n",
        "    Recall (H,C,E):\n",
        "         [0.9478 0.1807 0.0529] \n",
        "\n",
        "    Counts (H,C,E) x (H,C,E):\n",
        "    [[41904  1686   623]\n",
        "     [37278  8435   969]\n",
        "     [20351  3548  1335]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbb468c0",
      "metadata": {
        "id": "bbb468c0",
        "outputId": "59dc3ea4-6d9a-4829-9d98-b700927e6320"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Decoding sequences: 100%|██████████| 537/537 [01:28<00:00,  6.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time predict on dev data is approx: 89.06 seconds\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "dev_predictions = getPredictions(dev_df_formatted, T, E, pi, state_symbols, state_decode, possible_priors)\n",
        "dev_acc, dev_prec, dev_rec, dev_cnts = HMMaccuracy(dev_predictions, state_decode, state_symbols)\n",
        "end = time.time()\n",
        "print(f\"Time predict on dev data is approx: {round((end-start),2)} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f1852e2",
      "metadata": {
        "id": "6f1852e2",
        "outputId": "6ac5735e-d6ff-4dae-a6d3-eebf5ba802f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5499 \n",
            "\n",
            "Precision (H,C,E):\n",
            "\t [0.5005 0.6528 0.6142] \n",
            "\n",
            "Recall (H,C,E):\n",
            "\t [0.8695 0.4576 0.1664] \n",
            "\n",
            "Counts (H,C,E) x (H,C,E):\n",
            "[[38331  4754  1000]\n",
            " [23433 21184  1675]\n",
            " [14822  6513  4259]]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy: {round(dev_acc,4)} \\n\")\n",
        "print(f\"Precision (H,C,E):\\n\\t {dev_prec.round(decimals = 4)} \\n\")\n",
        "print(f\"Recall (H,C,E):\\n\\t {dev_rec.round(decimals = 4)} \\n\")\n",
        "print(\"Counts (H,C,E) x (H,C,E):\")\n",
        "print(dev_cnts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4d5ab2a",
      "metadata": {
        "id": "f4d5ab2a"
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "cs_hmm_pendo.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}