{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cc542f1e",
      "metadata": {
        "id": "cc542f1e"
      },
      "source": [
        "# Predicting Q3 Protein Secondary Structure Using a Traditional HMM\n",
        "### COMS 4761 - Project\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qEd3tPtiZrFY",
      "metadata": {
        "id": "qEd3tPtiZrFY"
      },
      "source": [
        "### Step 0: Create All Functions that Will Be Used Downstream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61414971",
      "metadata": {
        "id": "61414971"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f85917b6",
      "metadata": {
        "id": "f85917b6"
      },
      "outputs": [],
      "source": [
        "def get_data(arr, residue_list, q8_list, columns, r, f, bounds=None):\n",
        "    \n",
        "    \"\"\"\n",
        "    This function retrieves and formats data from the CB6133_filtered and CB531 datasets [1][2]\n",
        "    Codes is slighlty modified from code provided by [3][4]\n",
        "    \n",
        "    [1] Jian Zhou and Olga G. Troyanskaya. Deep supervised and convolutional generative stochastic network for\n",
        "        protein s\n",
        "    [2] Jian Zhou and Olga G. Troyanskaya. CB6133 dataset.\n",
        "        https://www.princeton.edu/~jzthree/datasets/ICML2014/dataset_readme.txt, 2014.\n",
        "    [3] Iddo Drori et al. High Quality Prediction of Protein Q8 Secondary Structure by\n",
        "        Diverse Neural Network Architectures. arXiv preprint arXiv:1811.07143, 2018\n",
        "    [4] https://github.com/idrori/cu-ssp/blob/master/model_1/model_1.py\n",
        "    \"\"\"\n",
        "    \n",
        "    if bounds is None: bounds = range(len(arr))\n",
        "    \n",
        "    data = [None for i in bounds]\n",
        "    for i in bounds:\n",
        "        seq, q8, q3, q2, profiles = '', '', '', '', []\n",
        "        for j in range(r):\n",
        "            jf = j*f\n",
        "            \n",
        "            # Residue convert from one-hot to decoded\n",
        "            residue_onehot = arr[i,jf+0:jf+22]\n",
        "            residue = residue_list[np.argmax(residue_onehot)]\n",
        "\n",
        "            # Q8 one-hot encoded to decoded structure symbol\n",
        "            residue_q8_onehot = arr[i,jf+22:jf+31]\n",
        "            residue_q8 = q8_list[np.argmax(residue_q8_onehot)]\n",
        "\n",
        "            if residue == 'NoSeq': break      # terminating sequence symbol\n",
        "\n",
        "            nc_terminals = arr[i,jf+31:jf+33] # nc_terminals = [0. 0.]\n",
        "            sa = arr[i,jf+33:jf+35]           # sa = [0. 0.]\n",
        "            profile = arr[i,jf+35:jf+57]      # profile features\n",
        "            \n",
        "            seq += residue # concat residues into amino acid sequence\n",
        "            #encode q3 structure\n",
        "            if residue_q8 in 'GHI':\n",
        "                q3 += 'H'\n",
        "                q2 += 'A'\n",
        "            elif residue_q8 in 'E':\n",
        "                q3 += 'E'\n",
        "                q2 += 'X'\n",
        "            else:\n",
        "                q3 += 'C'\n",
        "                q2 += 'X'\n",
        "            \n",
        "            q8  += residue_q8 # concat secondary structure into secondary structure sequence\n",
        "            profiles.append(profile)\n",
        "        \n",
        "        data[i] = [str(i+1), len(seq), seq, np.array(profiles), q8, q3, q2]\n",
        "    \n",
        "    return pd.DataFrame(data, columns=columns)\n",
        "\n",
        "\n",
        "def encode_sequence(sequence, code):\n",
        "    \n",
        "    \"\"\"\n",
        "    Provided an input sequence and a code, returns the encoding of the sequence\n",
        "    \"\"\"\n",
        "    \n",
        "    encoded_seq = []\n",
        "    \n",
        "    for x in sequence:\n",
        "        try:\n",
        "            idx = code[x]\n",
        "            encoded_seq.append(idx)\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            break\n",
        "    \n",
        "    return encoded_seq\n",
        "\n",
        "\n",
        "def format_dataset(df, emission_code, state_code, exp_col=\"q3_expected\"):\n",
        "    \n",
        "    \"\"\"\n",
        "    Provided a dataframe which contains the amino sequences and the hidden sequence,\n",
        "    this function encodes those sequences according to the provided codes\n",
        "    and return them\n",
        "    \n",
        "    *exp_col specifies if want to encode the q8, q3, or q2 hidden sequence\n",
        "    \"\"\"\n",
        "    \n",
        "    assert ('id' in df.columns and 'len' in df.columns and 'input' in df.columns and exp_col in df.columns)\n",
        "    \n",
        "    formattedDF = pd.DataFrame(columns=['id','len','input','expected'])\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        \n",
        "        sid = df.iloc[i].id\n",
        "        slen = df.iloc[i].len\n",
        "        enc_input = encode_sequence(df.iloc[i].input, emission_code)\n",
        "        enc_expected = encode_sequence(df.iloc[i][exp_col], state_code)\n",
        "        \n",
        "        assert (len(enc_input) == len(enc_expected))\n",
        "        \n",
        "        formattedDF = formattedDF.append({'id':sid, 'len':slen, 'input':enc_input, 'expected':enc_expected}, ignore_index=True)\n",
        "\n",
        "    return formattedDF\n",
        "\n",
        "def estimate_transition_matrix(df, state_code):\n",
        "    \"\"\"\n",
        "    Given a dataframe that has the data for the amino sequences and their corresponding hidden sequence,\n",
        "    we use the data to compute the MLEs of the emission probablities.\n",
        "    \n",
        "    ex. estimated P(emission=A|state=H) = count(emission=A,state=H) / sum_over_all_emission count(emission, state=H)\n",
        "    \n",
        "    *implemented a pseudocount of +1 for cases where we have 0 observations of a certain (emission,state) combo\n",
        "    \"\"\"\n",
        "    \n",
        "    n_states = len(state_code)\n",
        "    \n",
        "    #using pseudocount of +1\n",
        "    counts = np.ones(shape=(n_states, n_states), dtype=float)\n",
        "    \n",
        "    for i in range(len(df)):\n",
        "        \n",
        "        state_seq = df.iloc[i].expected\n",
        "        seq_len = df.iloc[i].len\n",
        "        \n",
        "        for j in range(seq_len - 1):\n",
        "            \n",
        "            x = state_seq[j]\n",
        "            y = state_seq[j+1]\n",
        "            \n",
        "            counts[x,y] += 1\n",
        "    \n",
        "    #transform counts to probability by normalizing of row sums\n",
        "    row_sums = np.sum(counts, axis=1)\n",
        "    T = counts / row_sums.reshape((-1,1))\n",
        "    \n",
        "    return T\n",
        "\n",
        "\n",
        "def estimate_emission_matrix(df, state_code, emission_code):\n",
        "    \"\"\"\n",
        "    Given a dataframe that has the data for the amino sequences and their corresponding hidden sequence,\n",
        "    we use the data to compute the MLEs of the transition probablities.\n",
        "    \n",
        "    ex. estimated P(state_{t+1}=E|state_{t}=H) = count(state_{t}=H, state_{t+1}=E) / sum_over_all_states count(state_{t}=H, state_{t+1})\n",
        "    \n",
        "    *implemented a pseudocount of +1 for cases where we have 0 observations of a certain (state,state) combo\n",
        "    \"\"\"\n",
        "    \n",
        "    n_states = len(state_code)\n",
        "    n_emissions = len(emission_code)\n",
        "    \n",
        "    #using pseudocount of +1\n",
        "    counts = np.ones(shape=(n_states, n_emissions), dtype=float)\n",
        "    \n",
        "    for i in range(len(df)):\n",
        "        \n",
        "        state_seq = df.iloc[i].expected\n",
        "        emission_seq = df.iloc[i].input\n",
        "        seq_len = df.iloc[i].len\n",
        "        \n",
        "        for j in range(seq_len):\n",
        "            \n",
        "            x = state_seq[j]\n",
        "            y = emission_seq[j]\n",
        "            \n",
        "            counts[x,y] += 1\n",
        "\n",
        "    #transform counts to probability by normalizing of row sums\n",
        "    row_sums = np.sum(counts, axis=1)\n",
        "    E = counts / row_sums.reshape((-1,1))\n",
        "    \n",
        "    return E\n",
        "\n",
        "def start_distribution(df,state_code):\n",
        "    \"\"\"\n",
        "    Given a dataframe that has the data for the amino sequences and their corresponding hidden sequence,\n",
        "    we use the data to compute the MLEs of the start distribution.\n",
        "    \n",
        "    ex. estimated P(state=H) = count(state=H) / sum_over_all_states count(state)\n",
        "    \n",
        "    *implemented a pseudocount of +1 for cases where we have 0 observations of a certain state\n",
        "    \"\"\"\n",
        "    \n",
        "    n_states = len(state_code)\n",
        "    \n",
        "    #using pseudocount of +1\n",
        "    counts = np.array([1.0] * n_states)\n",
        "    \n",
        "    for i in range(len(df)):\n",
        "        \n",
        "        state_seq = df.iloc[i].expected\n",
        "        seq_len = df.iloc[i].len\n",
        "        \n",
        "        for j in range(seq_len):\n",
        "            \n",
        "            x = state_seq[j]\n",
        "            \n",
        "            counts[x] += 1\n",
        "    \n",
        "    #transform counts to probability by normalizing of row sums\n",
        "    total = sum(counts)\n",
        "    pi = counts / total\n",
        "    \n",
        "    return pi\n",
        "\n",
        "def viterbi_decoding(T,E,pi,seq):\n",
        "    \"\"\"\n",
        "    This functions performs viterbi decoding to get the predicted hidden sequence,\n",
        "    given the input emission sequence as well as the transition matrix, emission matrix,\n",
        "    and the start distribution\n",
        "    \"\"\"\n",
        "    \n",
        "    #sequence length\n",
        "    N = len(seq)\n",
        "    #num of states\n",
        "    M = T.shape[0]\n",
        "    \n",
        "    assert (M == len(pi))\n",
        "    \n",
        "    #V will store viterbi values\n",
        "    V = np.zeros(shape=(M, N), dtype=float)\n",
        "    \n",
        "    #P will store prev state from which we transitioned into state m and time n to achieve the max value of V[m,n]\n",
        "    #(i.e. pointer to help us reconstruct sequence after predicting most probable path in viterbi graph)\n",
        "    P = np.empty(shape=(M, N))\n",
        "    P[:] = np.NaN\n",
        "    \n",
        "    #populate viterbi matrix\n",
        "    for n in range(N):\n",
        "        \n",
        "        #get current emissions\n",
        "        e = seq[n]\n",
        "        \n",
        "        for m in range(M):\n",
        "            \n",
        "            #initilize viterbi value for current timestep given state m to be -infty\n",
        "            maxV = float(\"-inf\")\n",
        "            prev = np.NaN\n",
        "            \n",
        "            #get log prob. of emission given state m\n",
        "            emiss_logp = np.log(E[m,e])\n",
        "            \n",
        "            #start of sequence\n",
        "            if n == 0:\n",
        "                start_logp = np.log(pi[m])\n",
        "                maxV = emiss_logp + start_logp\n",
        "                \n",
        "            else:\n",
        "            \n",
        "                #solve for max value for V[m,n]\n",
        "                for i in range(M): \n",
        "\n",
        "                    #get previous timestep viterbi value for state i (which should be a log prob)\n",
        "                    prev_vit = V[i, n-1]\n",
        "\n",
        "                    #get log prob of transition from state i to m\n",
        "                    trans_logp = np.log(T[i,m])\n",
        "\n",
        "                    #update viterbi value for current timestep given state m\n",
        "                    curV = prev_vit + trans_logp + emiss_logp\n",
        "\n",
        "                    if curV > maxV:\n",
        "                        maxV = curV\n",
        "                        prev = i\n",
        "        \n",
        "            V[m,n] = maxV\n",
        "            P[m,n] = prev\n",
        "    \n",
        "    #initialize with state with highest probability at end of sequence\n",
        "    best_path = [np.argmax(V[:,-1])]\n",
        "    \n",
        "    #work backwards to reconstruct sequence\n",
        "    for n in range(N-1,0,-1):\n",
        "        \n",
        "        #determine where we are\n",
        "        cur_state = best_path[0]\n",
        "\n",
        "        #find state from which we came that yielded highest probability to current state at current time\n",
        "        prev_state = int(P[cur_state,n])\n",
        "\n",
        "        #prepend previous state\n",
        "        best_path = [prev_state] + best_path\n",
        "    \n",
        "    return best_path\n",
        "\n",
        "\n",
        "def getPredictions(df, T, E, pi):\n",
        "    \n",
        "    \"\"\"\n",
        "    get predictions for all sequences in specified dataset using provided HMM\n",
        "    \"\"\"\n",
        "    \n",
        "    results = pd.DataFrame(columns=['input','predicted','expected'])\n",
        "    \n",
        "    for i in range(len(df)):\n",
        "        \n",
        "        amino_seq = df.iloc[i].input\n",
        "        pred_seq = viterbi_decoding(T,E,pi,amino_seq)\n",
        "        exp_seq = df.iloc[i].expected\n",
        "        \n",
        "        assert(len(amino_seq) == len(pred_seq) and len(amino_seq) == len(exp_seq))\n",
        "        \n",
        "        results = results.append({'input':amino_seq, 'predicted':pred_seq, 'expected':exp_seq}, ignore_index=True)\n",
        "    \n",
        "    return results\n",
        "\n",
        "def HMMaccuracy(df,q=3):\n",
        "    \n",
        "    \"\"\"\n",
        "    Compute accurcay of HMM given a dataframe the has the input emission sequences,\n",
        "    the predicted hidden sequences, and the actual hidden sequences\n",
        "    \n",
        "    *q specifies whether the predicion was made for q2, q3, or q8 protein structure\n",
        "    \"\"\"\n",
        "    \n",
        "    #row represents expected state\n",
        "    #col represents predicted state\n",
        "    counts = np.zeros(shape=(q,q), dtype=int)\n",
        "    \n",
        "    for i in range(len(df)):\n",
        "\n",
        "        #get predicted and expected hidden sequence from dataframe\n",
        "        pred = df.iloc[i].predicted\n",
        "        exp = df.iloc[i].expected\n",
        "        \n",
        "        assert (len(pred) == len(exp))\n",
        "        \n",
        "        for j in range(len(pred)):\n",
        "            \n",
        "            x = exp[j]\n",
        "            y = pred[j]\n",
        "            counts[x,y] += 1\n",
        "    \n",
        "    rowSum = np.sum(counts, axis=1)\n",
        "    colSum = np.sum(counts, axis=0)\n",
        "    \n",
        "    #true positive (negative) / total predicted positive (negative)\n",
        "    precision = np.array([counts[i,i] / colSum[i] for i in range(q)])\n",
        "    \n",
        "    #true positive (negative) / total actual positive (negative)\n",
        "    recall = np.array([counts[i,i] / rowSum[i] for i in range(q)])\n",
        "    \n",
        "    accuracy = 0\n",
        "    for i in range(q):\n",
        "        accuracy += counts[i,i]\n",
        "    accuracy = accuracy / sum(rowSum)\n",
        "    \n",
        "    \n",
        "    return accuracy, precision, recall, counts\n",
        "       \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84016ffa",
      "metadata": {
        "id": "84016ffa"
      },
      "source": [
        "### Step 1: Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7c6301c",
      "metadata": {
        "id": "b7c6301c",
        "outputId": "87c53588-28b5-44c7-d843-981c97e005e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Loaded\n",
            "CB6133 shape: (5365, 39900)\n",
            "CB513 shape: (514, 39900)\n"
          ]
        }
      ],
      "source": [
        "#seed so get consistent results for every run\n",
        "random.seed(0)\n",
        "\n",
        "cb513 = np.load('cb513+profile_split1.npy.gz')\n",
        "cb6133filtered = np.load('cullpdb+profile_5926_filtered.npy.gz')\n",
        "print(\"Data Loaded\")\n",
        "print(f\"CB6133 shape: {cb6133filtered.shape}\")\n",
        "print(f\"CB513 shape: {cb513.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1615fa3a",
      "metadata": {
        "id": "1615fa3a"
      },
      "source": [
        "### Step 2: Process Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the dataset into train, dev, and test sets."
      ],
      "metadata": {
        "id": "QEfRAiDbqdbA"
      },
      "id": "QEfRAiDbqdbA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fe200e2",
      "metadata": {
        "id": "0fe200e2",
        "outputId": "cdbd89cc-d7c9-43dc-bc93-2a6642035431"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Turning data arrays into dataframes\n"
          ]
        }
      ],
      "source": [
        "maxlen_seq = r = 700 # protein residues padded to 700\n",
        "f = 57  # number of features for each residue\n",
        "residue_list = list('ACEDGFIHKMLNQPSRTWVYX') + ['NoSeq']\n",
        "q8_list      = list('LBEGIHST') + ['NoSeq']\n",
        "q3_list      = list('HCE') + ['NoSeq']\n",
        "q2_list      = list('AX') + ['NoSeq']\n",
        "\n",
        "columns = [\"id\", \"len\", \"input\", \"profiles\", \"q8_expected\", \"q3_expected\", \"q2_expected\"]\n",
        "\n",
        "print(\"Turning data arrays into dataframes\")\n",
        "\n",
        "# train, dev, test split\n",
        "# break out 10% of train data to be used as dev set\n",
        "train_df, dev_df = train_test_split(get_data(cb6133filtered, residue_list, q8_list, columns, r, f), test_size=0.1, random_state=11)\n",
        "test_df  = get_data(cb513, residue_list, q8_list, columns, r, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a957da8",
      "metadata": {
        "id": "5a957da8"
      },
      "source": [
        "### Step 3: Encode Sequences and Format DataFrames\n",
        "    (a) Create codes to encode emission and hidden sequences\n",
        "    (b) Apply encodings & specify hidden sequence of interest (q2, q3, q8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8ab1e14",
      "metadata": {
        "id": "e8ab1e14",
        "outputId": "1ab2be08-1a4d-4765-8a51-e5387f6d2f72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "emission_code:\n",
            "A:0 C:1 E:2 D:3 G:4 F:5 I:6 H:7 K:8 M:9 L:10 N:11 Q:12 P:13 S:14 R:15 T:16 W:17 V:18 Y:19 X:20 \n",
            "\n",
            "state_code:\n",
            "H:0 C:1 E:2 "
          ]
        }
      ],
      "source": [
        "emission_code = {residue_list[i]:i for i in range(len(residue_list)-1)}\n",
        "state_code = {q3_list[i]:i for i in range(len(q3_list)-1)}\n",
        "\n",
        "print(\"emission_code:\")\n",
        "for k,v in emission_code.items():\n",
        "    print(f\"{k}:{v}\", end=\" \")\n",
        "\n",
        "print(\"\\n\\nstate_code:\")\n",
        "for k,v in state_code.items():\n",
        "    print(f\"{k}:{v}\", end=\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5710e4c7",
      "metadata": {
        "id": "5710e4c7",
        "outputId": "f5f90d86-55e0-4f82-d0cd-ccc9e1a349de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding sequences\n"
          ]
        }
      ],
      "source": [
        "print(\"Encoding sequences\")\n",
        "train_df_formatted = format_dataset(train_df, emission_code, state_code, 'q3_expected')\n",
        "dev_df_formatted = format_dataset(dev_df, emission_code, state_code, 'q3_expected')\n",
        "test_df_formatted = format_dataset(test_df, emission_code, state_code, 'q3_expected')    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26e643f4",
      "metadata": {
        "id": "26e643f4"
      },
      "source": [
        "### Step 4: Estimate HMM=(T, E, pi) using Our Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77350157",
      "metadata": {
        "id": "77350157",
        "outputId": "44da7bcd-ac73-4486-d367-d7b1eda3eaab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing initial estimates for transition and emission matrices using training data\n",
            "Time to estimate T, E, pi is approx: 0.0 minutes\n"
          ]
        }
      ],
      "source": [
        "print(\"Computing initial estimates for transition and emission matrices using training data\")\n",
        "start = time.time()\n",
        "T = estimate_transition_matrix(train_df_formatted, state_code)\n",
        "E = estimate_emission_matrix(train_df_formatted, state_code, emission_code)\n",
        "pi = start_distribution(train_df_formatted,state_code)\n",
        "end = time.time()\n",
        "print(f\"Time to estimate T, E, pi is approx: {round((end-start)//60,4)} minutes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61efbc7c",
      "metadata": {
        "id": "61efbc7c"
      },
      "source": [
        "### Step 5: Compare HMM against Prior Research [5]\n",
        "\n",
        "    Some slight difference is expected because they were only able to train and test on CB531 whereas we will be training on CB6113 and testing on CB531.\n",
        "\n",
        "    [5] W. Ding, D. Dai, J. Xie, H. Zhang, W. Zhang and H. Xie, \"PRT-HMM: A Novel Hidden Markov Model for Protein Secondary Structure Prediction,\" 2012 IEEE/ACIS 11th International Conference on Computer and Information Science, 2012, pp. 207-212, doi: 10.1109/ICIS.2012.89.\n",
        "\n",
        "    https://ieeexplore-ieee-org.ezproxy.cul.columbia.edu/stamp/stamp.jsp?tp=&arnumber=6211098\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1d3362a",
      "metadata": {
        "id": "c1d3362a",
        "outputId": "f67b5010-f797-48fd-9352-2bb883b3b932"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start Distribution (H,C,E):\n",
            "[0.3863 0.3968 0.2169]\n"
          ]
        }
      ],
      "source": [
        "print(\"Start Distribution (H,C,E):\")\n",
        "print(pi.round(decimals=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fc70fb2",
      "metadata": {
        "id": "3fc70fb2",
        "outputId": "74171582-c705-4678-c346-7e721dd73d0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.0367, -0.0437,  0.0069])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#compare start distribution to source\n",
        "pi_source = np.array([0.3496, 0.4405, 0.2100] )\n",
        "pi_delta = (pi - pi_source).round(decimals=4)\n",
        "pi_delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed570bd5",
      "metadata": {
        "id": "ed570bd5",
        "outputId": "b298086d-09ce-4d4a-9452-071c2fddcc7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transition Matrix (H,C,E) x (H,C,E):\n",
            "[[0.8989 0.0982 0.0028]\n",
            " [0.0944 0.8081 0.0975]\n",
            " [0.0093 0.172  0.8186]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Transition Matrix (H,C,E) x (H,C,E):\")\n",
        "print(T.round(decimals=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b6456ec",
      "metadata": {
        "id": "5b6456ec",
        "outputId": "709b9aff-d21b-4c16-f434-bedb74d1be32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.0052, -0.0054,  0.0001],\n",
              "       [ 0.0134, -0.0216,  0.0082],\n",
              "       [ 0.0002, -0.0081,  0.0078]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#compare transition matrix to source\n",
        "T_source = np.array( \\\n",
        "    [[0.8937, 0.1036, 0.0027], \\\n",
        "     [0.0810, 0.8297, 0.0893], \\\n",
        "     [0.0091, 0.1801, 0.8108 ]]\n",
        "    )\n",
        "\n",
        "T_delta = (T - T_source).round(decimals=4)\n",
        "T_delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88ef0087",
      "metadata": {
        "id": "88ef0087",
        "outputId": "70445764-8ad7-46da-f649-4892768ef62b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Emissions Matrix (H,C,E) x Amino Acids:\n",
            "[[0.1138 0.0103 0.0929 0.0522 0.0357 0.0406 0.0578 0.0208 0.0655 0.0192\n",
            "  0.1193 0.0328 0.0478 0.0244 0.0485 0.0596 0.0414 0.0149 0.0602 0.035\n",
            "  0.0074]\n",
            " [0.0641 0.012  0.0569 0.0814 0.1195 0.032  0.035  0.026  0.0559 0.013\n",
            "  0.0633 0.0617 0.0324 0.0796 0.0736 0.0445 0.0596 0.0109 0.0452 0.0282\n",
            "  0.0054]\n",
            " [0.0636 0.016  0.0478 0.0329 0.0475 0.058  0.1008 0.0232 0.0454 0.0155\n",
            "  0.1035 0.0259 0.0282 0.0191 0.0511 0.0462 0.0657 0.0182 0.1339 0.0503\n",
            "  0.0072]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Emissions Matrix (H,C,E) x Amino Acids:\")\n",
        "print(E.round(decimals=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddb7628f",
      "metadata": {
        "id": "ddb7628f",
        "outputId": "84ce143b-f075-4e9e-c292-9245f688f169"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.008 , -0.046 ,  0.0564, -0.0009,  0.0231, -0.0449,  0.0078,\n",
              "        -0.0164,  0.0459, -0.0356,  0.0077, -0.0351,  0.0215, -0.0147,\n",
              "         0.0241,  0.0104, -0.0019, -0.0004,  0.0249, -0.0253],\n",
              "       [-0.0045, -0.0286, -0.0057,  0.0027,  0.1029, -0.0182,  0.0029,\n",
              "        -0.0979,  0.0317, -0.0223,  0.003 ,  0.0039,  0.0172,  0.0478,\n",
              "        -0.0039, -0.0292, -0.004 , -0.0004,  0.016 , -0.0187],\n",
              "       [-0.0028, -0.0254,  0.02  ,  0.0014,  0.0255,  0.0162,  0.0729,\n",
              "        -0.0296,  0.0228, -0.0811,  0.0032, -0.0213,  0.0067, -0.0346,\n",
              "         0.0319, -0.0081, -0.0086, -0.0005,  0.0854, -0.0812]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#compare emission matrix to source\n",
        "E_source = np.array( \\\n",
        "    [[0.1218, 0.0686, 0.0664], \\\n",
        "    [0.0563, 0.0406, 0.0414], \\\n",
        "    [0.0365, 0.0626, 0.0278], \\\n",
        "    [0.0531, 0.0787, 0.0315], \\\n",
        "    [0.0126, 0.0166, 0.0220], \\\n",
        "    [0.0855, 0.0502, 0.0418], \\\n",
        "    [0.0500, 0.0321, 0.0279], \\\n",
        "    [0.0372, 0.1239, 0.0528], \\\n",
        "    [0.0196, 0.0242, 0.0226], \\\n",
        "    [0.0548, 0.0353, 0.0966], \\\n",
        "    [0.1116, 0.0603, 0.1003], \\\n",
        "    [0.0679, 0.0578, 0.0472], \\\n",
        "    [0.0263, 0.0152, 0.0215], \\\n",
        "    [0.0391, 0.0318, 0.0537], \\\n",
        "    [0.0244, 0.0775, 0.0192], \\\n",
        "    [0.0492, 0.0737, 0.0543], \\\n",
        "    [0.0433, 0.0636, 0.0743], \\\n",
        "    [0.0153, 0.0113, 0.0187], \\\n",
        "    [0.0353, 0.0292, 0.0485], \\\n",
        "    [0.0603, 0.0469, 0.1315]]\n",
        "    )\n",
        "\n",
        "#source does not have emission for X amino acid label\n",
        "E_delta = (E[:,:-1] - E_source.T).round(decimals=4)\n",
        "E_delta"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b020dba0",
      "metadata": {
        "id": "b020dba0"
      },
      "source": [
        "### Step 6: Compute HMM Prediction Performance on Train Data\n",
        "    We can compare against performance of traditional HMM from [5] as sanity check:\n",
        "        Overall Accuracy: 44.38%\n",
        "        Helix Accuracy (H): 90.46%\n",
        "        Beta-Sheet Accuracy (E): 4.56%\n",
        "        Coil Accuracy (C): 28.05%\n",
        "        \n",
        "     *Some slight difference is expected because they were only able to train and test on CB531 whereas we will be training on CB6113 and testing on CB531.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40bdb77c",
      "metadata": {
        "id": "40bdb77c",
        "outputId": "34ee147c-adbd-47d9-b9f8-c2fe986687af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time predict on training data is approx: 25.9 seconds\n"
          ]
        }
      ],
      "source": [
        "#make predictions\n",
        "start = time.time()\n",
        "train_predictions = getPredictions(train_df_formatted, T, E, pi)\n",
        "train_acc, train_prec, train_rec, train_cnts = HMMaccuracy(train_predictions, q=3)\n",
        "end = time.time()\n",
        "print(f\"Time predict on training data is approx: {round((end-start),2)} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90bdaeeb",
      "metadata": {
        "id": "90bdaeeb",
        "outputId": "6223f9d7-53fa-436c-9ba0-1729300d6e52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.4487 \n",
            "\n",
            "Precision (H,C,E):\n",
            "\t [0.425  0.6161 0.472 ] \n",
            "\n",
            "Recall (H,C,E):\n",
            "\t [0.9461 0.1838 0.0472] \n",
            "\n",
            "Counts (H,C,E) x (H,C,E):\n",
            "[[379538  16968   4655]\n",
            " [329085  75752   7233]\n",
            " [184338  30243  10629]]\n"
          ]
        }
      ],
      "source": [
        "#Our HMM performance\n",
        "\n",
        "print(f\"Accuracy: {round(train_acc,4)} \\n\")\n",
        "print(f\"Precision (H,C,E):\\n\\t {train_prec.round(decimals = 4)} \\n\")\n",
        "print(f\"Recall (H,C,E):\\n\\t {train_rec.round(decimals = 4)} \\n\")\n",
        "print(\"Counts (H,C,E) x (H,C,E):\")\n",
        "print(train_cnts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52e28d87",
      "metadata": {
        "id": "52e28d87"
      },
      "source": [
        "### Step 7: Compute HMM Performance on Dev Data\n",
        "    We can compare against performance of traditional HMM from [5] as sanity check:\n",
        "            Overall Accuracy: 44.38%\n",
        "            Helix Accuracy (H): 90.46%\n",
        "            Beta-Sheet Accuracy (E): 4.56%\n",
        "            Coil Accuracy (C): 28.05%\n",
        "        \n",
        "     *Some slight difference is expected because they were only able to train and test on CB531 whereas we will be training on CB6113 and testing on CB531."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "275b56c6",
      "metadata": {
        "id": "275b56c6",
        "outputId": "337e3b52-7e3b-483b-8a2c-06444cd611bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time predict on dev data is approx: 2.9 seconds\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "dev_predictions = getPredictions(dev_df_formatted, T, E, pi)\n",
        "dev_acc, dev_prec, dev_rec, dev_cnts = HMMaccuracy(dev_predictions, q=3)\n",
        "end = time.time()\n",
        "print(f\"Time predict on dev data is approx: {round((end-start),2)} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ed6871b",
      "metadata": {
        "id": "3ed6871b",
        "outputId": "6507ca16-da10-4e76-ee29-7cdb3acc412f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.4498 \n",
            "\n",
            "Precision (H,C,E):\n",
            "\t [0.423  0.6198 0.4801] \n",
            "\n",
            "Recall (H,C,E):\n",
            "\t [0.9399 0.1989 0.0594] \n",
            "\n",
            "Counts (H,C,E) x (H,C,E):\n",
            "[[41435  1999   651]\n",
            " [36090  9206   996]\n",
            " [20424  3649  1521]]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy: {round(dev_acc,4)} \\n\")\n",
        "print(f\"Precision (H,C,E):\\n\\t {dev_prec.round(decimals = 4)} \\n\")\n",
        "print(f\"Recall (H,C,E):\\n\\t {dev_rec.round(decimals = 4)} \\n\")\n",
        "print(\"Counts (H,C,E) x (H,C,E):\")\n",
        "print(dev_cnts)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "traditional_hmm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}